llm_name,BERTScore F1,SBERT Similarity,LLM Answer Similarity,Rejection Accuracy,Judge: Rephrase Quality,Judge: Answer Correctness
DeepSeek-R1,0.8936281631795727,0.7779307091646657,0.45521094200144313,0.6816326530612244,3.916326530612245,4.497448979591836
GPT-4.1,0.9263401144621324,0.8597471599961269,0.7531211985959386,0.7785714285714286,4.112244897959184,4.631122448979592
Llama-3.2-3B-Instruct,0.8955438408316398,0.742585853989027,0.7657065550293013,0.8270408163265306,4.009183673469388,4.147448979591837
