Model,Rephrase_Type,Rejection Accuracy,Jaccard Token,BERTScore,SBERT Similarity,LLM Judge
Llama-3.2-3B-Instruct,original,0.804,0.327,0.887,0.708,4.262
Llama-3.2-3B-Instruct,reverse,0.825,0.328,0.887,0.713,4.275
GPT-4.1,original,0.734,0.353,0.920,0.848,4.268
GPT-4.1,reverse,0.750,0.362,0.922,0.853,4.303
DeepSeek-R1,original,0.044,0.249,0.899,0.807,4.271
DeepSeek-R1,reverse,0.051,0.256,0.899,0.807,4.232
